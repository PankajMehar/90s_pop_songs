{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "activations = 128\n",
    "model_input = 'sweet dreams are made of these'\n",
    "n_chars = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "output_dir = 'data/'\n",
    "charset_file = '{}charset.csv'.format(output_dir)\n",
    "model_dir = 'model/100000ex-128a-50b-20c-2018-09-19 19:41:58.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# verify that a gpu is listed\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocessPrediction(ix_to_char, prediction):\n",
    "    index = np.argmax(prediction)\n",
    "    char = ix_to_char[index]\n",
    "    \n",
    "    return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCharacterConverters(chars):\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "    \n",
    "    return char_to_ix, ix_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessInput(char_to_ix, input, n_chars_set):\n",
    "    chars = list(input)\n",
    "    n_sample_chars = len(chars)\n",
    "\n",
    "    preprocessed_input = np.zeros((1, n_sample_chars, n_chars_set), dtype='float32')\n",
    "\n",
    "    for ci, char in enumerate(chars):\n",
    "        index = char_to_ix[char]\n",
    "        preprocessed_input[0][ci][index] = 1\n",
    "\n",
    "    return preprocessed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predictions(preds, temperature=0.5):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(charset_file, 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file, delimiter=\",\")\n",
    "    charset = []\n",
    "    for row in reader:\n",
    "        charset.append(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Charset Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionarys\n",
    "char_to_ix, ix_to_char = generateCharacterConverters(charset)\n",
    "n_charset = len(charset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a sequence from a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert input to a sequence of one-hot encoded chars\n",
    "preprocessed_input = preprocessInput(char_to_ix, model_input, n_charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = model_input\n",
    "\n",
    "for i in range(n_chars):\n",
    "    prediction = model.predict(preprocessed_input, verbose=0)[0]\n",
    "    sampled_prediction = sample_predictions(prediction)\n",
    "    next_char = deprocessPrediction(ix_to_char, sampled_prediction[0])\n",
    "    preprocessed_input[0][:-1] = preprocessed_input[0][1:]\n",
    "    preprocessed_input[0][-1] = sampled_prediction\n",
    "    result += next_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sweet dreams are made of these girl of a taits of your sings\n",
      "i'm sing the choon\n",
      "i can't say the little make me has all the same\n",
      "i know that you're the same\n",
      "i'll never the copponting to the chance to say so it to wanting that we're cry\n",
      "the ends of you\n",
      "and baby you sister\n",
      "in the may made me and eastly girl\n",
      "i can't could see it wish i'm so make you down that the hot so hart to say\n",
      "the player sings\n",
      "and when you say\n",
      "and i hopy to latter by\n",
      "the mind with you\n",
      "if you take a groor is the rind\n",
      "all the same of the chis the mance and th"
     ]
    }
   ],
   "source": [
    "sys.stdout.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
