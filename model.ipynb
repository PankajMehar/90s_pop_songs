{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "from IPython.display import SVG\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.layers import Dense, Input, LSTM\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "activations = 128\n",
    "batch_size = 50\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "training_ratio = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "output_dir = 'data/'\n",
    "charset_file = '{}charset.csv'.format(output_dir)\n",
    "dataset_file = '{}dataset.csv'.format(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# verify that a gpu is listed\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocessPrediction(ix_to_char, prediction):\n",
    "    index = np.argmax(prediction)\n",
    "    char = ix_to_char[index]\n",
    "    \n",
    "    return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCharacterConverters(chars):\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "    \n",
    "    return char_to_ix, ix_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateXYDatasets(char_to_ix, dataset, n_examples, n_charset, max_char_n):\n",
    "    # create training input\n",
    "    x_dataset = np.zeros((n_examples, max_char_n-1, n_charset), dtype='float32')\n",
    "    \n",
    "    # create training input\n",
    "    y_dataset = np.zeros((n_examples, n_charset), dtype='float32')\n",
    "    \n",
    "    # fill input training set with word sequences, where words are one-hot encoded\n",
    "    for li, line in enumerate(dataset):\n",
    "        for ci, char in enumerate(line[:-1]):\n",
    "            index = char_to_ix[char]\n",
    "            x_dataset[li][ci][index] = 1\n",
    "            \n",
    "    # create training output\n",
    "    for li, line in enumerate(dataset):\n",
    "        char = line[-1]\n",
    "        index = char_to_ix[char]\n",
    "        y_dataset[li][index] = 1\n",
    "        \n",
    "    return x_dataset, y_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessExample(char_to_ix, example, n_chars_set):\n",
    "    chars = list(example)\n",
    "    n_sample_chars = len(chars)\n",
    "\n",
    "    preprocessed_example = np.zeros((1, n_sample_chars, n_chars_set), dtype='float32')\n",
    "\n",
    "    for ci, char in enumerate(chars):\n",
    "        index = char_to_ix[char]\n",
    "        preprocessed_example[0][ci][index] = 1\n",
    "\n",
    "    return preprocessed_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predictions(preds, temperature=0.5):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(charset_file, 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file, delimiter=\",\")\n",
    "    charset = []\n",
    "    for row in reader:\n",
    "        charset.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_file, 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file, delimiter=\",\")\n",
    "    dataset = []\n",
    "    for row in reader:\n",
    "        dataset.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 60\n",
      "ix_to_char: {0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 14: '.', 15: '/', 16: ':', 17: ';', 18: '<', 19: '=', 20: '>', 21: '?', 22: '@', 23: '[', 24: '\\\\', 25: ']', 26: '^', 27: '_', 28: '`', 29: 'a', 30: 'b', 31: 'c', 32: 'd', 33: 'e', 34: 'f', 35: 'g', 36: 'h', 37: 'i', 38: 'j', 39: 'k', 40: 'l', 41: 'm', 42: 'n', 43: 'o', 44: 'p', 45: 'q', 46: 'r', 47: 's', 48: 't', 49: 'u', 50: 'v', 51: 'w', 52: 'x', 53: 'x', 54: 'y', 55: 'z', 56: '{', 57: '|', 58: '}', 59: '~'}\n",
      "char_to_ix: {'\\n': 0, ' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, '+': 11, ',': 12, '-': 13, '.': 14, '/': 15, ':': 16, ';': 17, '<': 18, '=': 19, '>': 20, '?': 21, '@': 22, '[': 23, '\\\\': 24, ']': 25, '^': 26, '_': 27, '`': 28, 'a': 29, 'b': 30, 'c': 31, 'd': 32, 'e': 33, 'f': 34, 'g': 35, 'h': 36, 'i': 37, 'j': 38, 'k': 39, 'l': 40, 'm': 41, 'n': 42, 'o': 43, 'p': 44, 'q': 45, 'r': 46, 's': 47, 't': 48, 'u': 49, 'v': 50, 'w': 51, 'x': 53, 'y': 54, 'z': 55, '{': 56, '|': 57, '}': 58, '~': 59}\n"
     ]
    }
   ],
   "source": [
    "# create dictionarys\n",
    "char_to_ix, ix_to_char = generateCharacterConverters(charset)\n",
    "n_charset = len(charset)\n",
    "\n",
    "print(\"Number of characters: {}\".format(n_charset))\n",
    "print(\"ix_to_char: {}\".format(ix_to_char))\n",
    "print(\"char_to_ix: {}\".format(char_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 39, 60)\n",
      "(1000, 60)\n"
     ]
    }
   ],
   "source": [
    "# create training input and output\n",
    "n_examples = len(dataset)\n",
    "max_char_n = len(dataset[0])\n",
    "x_dataset, y_dataset = generateXYDatasets(char_to_ix, dataset, n_examples, n_charset, max_char_n)\n",
    "print(\"Number of examples: {}\".format(n_examples))\n",
    "print(\"max characters: {}\".format(max_char_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_example shape: (39, 60)\n",
      "x_example one-hot: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "x_example: issed before\n",
      "trust in me\n",
      "time to put th\n"
     ]
    }
   ],
   "source": [
    "x_example = x_dataset[2] \n",
    "\n",
    "x_example_string = []\n",
    "for woh in x_example:\n",
    "    char = deprocessPrediction(ix_to_char, woh)\n",
    "    x_example_string.append(char)\n",
    "x_example_string_formatted = \"\".join(x_example_string)\n",
    "\n",
    "print(\"x_example shape: {}\".format(x_example.shape))\n",
    "print(\"x_example one-hot: {}\".format(x_example))\n",
    "print(\"x_example: {}\".format(x_example_string_formatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_example shape: (60,)\n",
      "y_example one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "y_example: e\n"
     ]
    }
   ],
   "source": [
    "y_example = y_dataset[2]\n",
    "\n",
    "char = deprocessPrediction(ix_to_char, y_example)\n",
    "\n",
    "print(\"y_example shape: {}\".format(y_example.shape))\n",
    "print(\"y_example one-hot: {}\".format(y_example))\n",
    "print(\"y_example: {}\".format(char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = Input(shape=(None, n_charset))\n",
    "x = LSTM(activations)(model_input)\n",
    "x = Dense(n_charset, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=model_input, outputs=x)\n",
    "\n",
    "optimizer = RMSprop(lr=learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up callbacks\n",
    "early = EarlyStopping(monitor='val_acc',\n",
    "                      min_delta=0,\n",
    "                      patience=10,\n",
    "                      verbose=1,\n",
    "                      mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate logging variables\n",
    "variant = '{}ex-{}a-{}b-{}c'.format(n_examples, activations, batch_size, max_char_n)\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "log_dir = 'logs/{}-{}'.format(variant, timestamp)\n",
    "diagram_dir = 'diagram/{}-{}'.format(variant, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 3.4463 - acc: 0.1143 - val_loss: 2.9838 - val_acc: 0.2000\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 3.0489 - acc: 0.1471 - val_loss: 2.9711 - val_acc: 0.2000\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 2.9982 - acc: 0.1571 - val_loss: 2.9484 - val_acc: 0.2167\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 2.8912 - acc: 0.1943 - val_loss: 2.8084 - val_acc: 0.2067\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 2.6860 - acc: 0.2371 - val_loss: 2.7156 - val_acc: 0.2600\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 2.5470 - acc: 0.2829 - val_loss: 2.6711 - val_acc: 0.2500\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 2.4110 - acc: 0.2986 - val_loss: 2.6460 - val_acc: 0.2533\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 2.2552 - acc: 0.3129 - val_loss: 2.6632 - val_acc: 0.2433\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 2.1423 - acc: 0.3471 - val_loss: 2.7210 - val_acc: 0.2667\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 1.9771 - acc: 0.3743 - val_loss: 2.7425 - val_acc: 0.2133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff307181da0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_dataset, \n",
    "          y_dataset, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          shuffle=True,\n",
    "          validation_split=training_ratio,\n",
    "          callbacks=[early, TensorBoard(log_dir=log_dir)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = 'sweet dreams are made of these'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert example to a sequence of one-hot encoded chars\n",
    "preprocessed_example = preprocessExample(char_to_ix, example, n_charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(preprocessed_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  \n"
     ]
    }
   ],
   "source": [
    "char = deprocessPrediction(ix_to_char, prediction[0])\n",
    "\n",
    "print(\"Prediction: {}\".format(char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a sequence from a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sweet dreams are made of these tourestole han\n",
      "sou\n",
      "yout lane you mat wan hane mat mat wind mat wone ang tou doure you gon mat ir you lesoteare hares ire mat wane you jone and care angeyou son\n",
      "you\n",
      "lane houe towe maure yeu kane here mat worese there heat wone at myt man myout in towon\n",
      "sowe toure i care and tou n wone toutseat wone you son\n",
      "at mytreat ingon mamone reyou goon\n",
      "eat wone touy you tom wann wang you dore hare hea\n",
      "d tou tor ter are and and ine ater\n",
      "yeat mon\n",
      "wone kooe tour le ire tou peate you han soon mares wa kare kyou"
     ]
    }
   ],
   "source": [
    "sys.stdout.write(example)\n",
    "\n",
    "for i in range(500):\n",
    "    prediction = model.predict(preprocessed_example, verbose=0)[0]\n",
    "    sampled_prediction = sample_predictions(prediction)\n",
    "    next_char = deprocessPrediction(ix_to_char, sampled_prediction[0])\n",
    "    preprocessed_example[0][:-1] = preprocessed_example[0][1:]\n",
    "    preprocessed_example[0][-1] = sampled_prediction\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 133.00 191.00\" width=\"133pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-187 129,-187 129,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140681772382976 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140681772382976</title>\n",
       "<polygon fill=\"none\" points=\"-7.10543e-15,-146.5 -7.10543e-15,-182.5 125,-182.5 125,-146.5 -7.10543e-15,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-160.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140681772382528 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140681772382528</title>\n",
       "<polygon fill=\"none\" points=\"13.5,-73.5 13.5,-109.5 111.5,-109.5 111.5,-73.5 13.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-87.8\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 140681772382976&#45;&gt;140681772382528 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140681772382976-&gt;140681772382528</title>\n",
       "<path d=\"M62.5,-146.313C62.5,-138.289 62.5,-128.547 62.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-119.529 62.5,-109.529 59.0001,-119.529 66.0001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140681772380960 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140681772380960</title>\n",
       "<polygon fill=\"none\" points=\"11.5,-0.5 11.5,-36.5 113.5,-36.5 113.5,-0.5 11.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-14.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140681772382528&#45;&gt;140681772380960 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140681772382528-&gt;140681772380960</title>\n",
       "<path d=\"M62.5,-73.3129C62.5,-65.2895 62.5,-55.5475 62.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"66.0001,-46.5288 62.5,-36.5288 59.0001,-46.5289 66.0001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a model diagram and save it to disk\n",
    "plot_model(model, to_file=diagram_dir)\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 60)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               96768     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                7740      \n",
      "=================================================================\n",
      "Total params: 104,508\n",
      "Trainable params: 104,508\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
